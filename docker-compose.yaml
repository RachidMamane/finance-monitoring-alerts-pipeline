services:
    zookeeper: 
        image: confluentinc/cp-zookeeper:7.4.0
        hostname: zookeeper
        container_name: zookeeper
        ports:
            - "2181:2181"
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000
        healthcheck:
            test: ['CMD','bash','-c', "echo 'Container is okay' | nc localhost 2181"]
            interval: 10s
            timeout: 5s
            retries: 5
        networks:
            - monitoring 
    
    broker:
        image: confluentinc/cp-server:7.4.0
        hostname: broker 
        container_name: kafka_broker
        depends_on:
            zookeeper:
                condition: service_healthy
        ports:
            - "9092:9092"
            - "9101:9101"
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
            KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
            KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
            KAFKA_JMX_PORT: 9101
            KAFKA_JMX_HOSTNAME: localhost
            KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
            CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:29092
            CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
            CONFLUENT_METRICS_ENABLE: 'false'
            CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
        networks:
            - monitoring
        healthcheck:
            test: ["CMD", "bash", "-c", 'nc -z localhost 9092']
            interval: 10s
            timeout: 5s
            retries: 5
    kafkaui:
        image: provectuslabs/kafka-ui 
        hostname: kafkaui 
        container_name: kafkaui 
        environment:
            KAFKA_CLUSTERS_0_NAME: 'local'
            KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: 'broker:29092'
            KAFKA_CLUSTERS_0_ZOOKEEPER: 'zookeeper:2181'
        depends_on:
            zookeeper: 
                condition: service_healthy
            broker:
                condition: service_healthy
        ports:
            - "9090:8080"
        networks:
            - monitoring
        healthcheck:
            test: ["CMD","bash","-c" ,'nc -z localhost 9090']
            interval: 10s
            timeout: 5s
            retries: 5
    redis: 
        image: redis:latest 
        hostname: redis 
        container_name: redis 
        ports:
            - "6379:6379"
        networks:
            - monitoring
        healthcheck:
            test: ["CMD","bash" , "-c", 'nc -z localhost 6379']
            interval: 10s
            timeout: 5s
            retries: 5
    elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:${ES_LOCAL_VERSION}
        container_name: es01
        volumes:
            - dev-elasticsearch:/usr/share/elasticsearch/data
        ports:
            - 127.0.0.1:${ES_LOCAL_PORT}:9200
        networks:
            - monitoring
        environment:
            - discovery.type=single-node
            - ELASTIC_PASSWORD=${ES_LOCAL_PASSWORD}
            - xpack.security.enabled=true
            - xpack.security.http.ssl.enabled=false
            - xpack.license.self_generated.type=trial
            - xpack.ml.use_auto_machine_memory_percent=true
            - ES_JAVA_OPTS=-Xms${ES_LOCAL_HEAP_INIT} -Xmx${ES_LOCAL_HEAP_MAX}
            - cluster.routing.allocation.disk.watermark.low=${ES_LOCAL_DISK_SPACE_REQUIRED}
            - cluster.routing.allocation.disk.watermark.high=${ES_LOCAL_DISK_SPACE_REQUIRED}
            - cluster.routing.allocation.disk.watermark.flood_stage=${ES_LOCAL_DISK_SPACE_REQUIRED}
        ulimits:
            memlock:
                soft: -1
                hard: -1
        healthcheck:
            test: [
                    "CMD-SHELL",
                    "curl --output /dev/null --silent --head --fail -u elastic:${ES_LOCAL_PASSWORD} http://elasticsearch:9200",
                ]
            interval: 10s
            timeout: 10s
            retries: 30
    kibana_settings:
        depends_on:
            elasticsearch:
                condition: service_healthy
        image: docker.elastic.co/elasticsearch/elasticsearch:${ES_LOCAL_VERSION}
        container_name: setting
        restart: 'no'
        networks:
            - monitoring
        command: >
            bash -c '
                echo "Setup the kibana_system password";
                start_time=$$(date +%s);
                timeout=60;
                until curl -s -u "elastic:${ES_LOCAL_PASSWORD}" -X POST http://elasticsearch:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_LOCAL_PASSWORD}\"}" -H "Content-Type: application/json" | grep -q "^{}"; do
                    if [ $$(($$(date +%s) - $$start_time)) -ge $$timeout ]; then
                        echo "Error: Elasticsearch timeout";
                        exit 1;
                    fi;
                    sleep 2;
                done;
                '
    kibana:
        depends_on:
            kibana_settings:
                condition: service_completed_successfully
        image: docker.elastic.co/kibana/kibana:${ES_LOCAL_VERSION}
        container_name: kibana
        volumes:
            - dev-kibana:/usr/share/kibana/data
            - ./config/telemetry.yml:/usr/share/kibana/config/telemetry.yml
        ports:
            - 127.0.0.1:${KIBANA_LOCAL_PORT}:5601
        environment:
            - SERVER_NAME=kibana
            - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
            - ELASTICSEARCH_USERNAME=kibana_system
            - ELASTICSEARCH_PASSWORD=${KIBANA_LOCAL_PASSWORD}
            - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${KIBANA_ENCRYPTION_KEY}
            - ELASTICSEARCH_PUBLICBASEURL=http://localhost:${ES_LOCAL_PORT}
        healthcheck:
            test:
                [
                    "CMD-SHELL",
                    "curl -s -I http://kibana:5601 | grep -q 'HTTP/1.1 302 Found'",
                ]
            interval: 10s
            timeout: 10s
            retries: 30
        networks:
            - monitoring
        
volumes:
  dev-elasticsearch:
  dev-kibana:





networks:
  monitoring:
